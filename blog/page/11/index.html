
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Steven's Blog</title>
  <meta name="author" content="Steven Sun">

  
  <meta name="description" content="&lt;Hadoop: The Definitive Guide, Fourth Edition&gt; http://hadoopbook.com 是本好书, 书中的例子用到了ncdc的数据ftp://ftp.ncdc.noaa.gov/pub/data/gsod/，这个也是非常赞的。 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://isunix.github.io/blog/page/11">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Steven's Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

<!-- MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  

</head>

<body    class="collapse-sidebar sidebar-footer" >
  <header role="banner"><hgroup>
  <h1><a href="/">Steven's Blog</a></h1>
  
    <h2>A Dream Land of Peace!</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:isunix.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about" class="nav-link">About Me</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2019/05/30/hadoopquan-wei-zhi-nan-ncdcshu-ju-zhun-bei-gong-zuo-bei-wang/">Hadoop权威指南ncdc数据准备工作备忘</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2019-05-30T09:23:39+08:00" pubdate data-updated="true">2019 年5 月30 日</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>&lt;Hadoop: The Definitive Guide, Fourth Edition&gt; <a href="http://hadoopbook.com">http://hadoopbook.com</a> 是本好书, 书中的例子用到了ncdc的数据<a href="ftp://ftp.ncdc.noaa.gov/pub/data/gsod/">ftp://ftp.ncdc.noaa.gov/pub/data/gsod/</a>，这个也是非常赞的。我们知道统计学大师Fisher当年就是在气象工作站，研究气象数据很多年，后来在统计学上面做出了卓越的成就。气象数据纷繁复杂，通过实际的气象数据来阅读这本书，会教会读者在真实的情况下，如何面对数据，这个要比用一些dummy数据做演示，效果好太多.</p>

<p>官网github上面的数据很少<a href="https://github.com/tomwhite/hadoop-book/tree/master/input/ncdc/all">https://github.com/tomwhite/hadoop-book/tree/master/input/ncdc/all</a>. 我们自己从上面的ncdc的链接中去下载，我们下载tar文件. 具体也可以参考这篇文章<a href="https://blog.csdn.net/mrcharles/article/details/50442367">https://blog.csdn.net/mrcharles/article/details/50442367</a></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c">#!/bin/bash</span>
</span><span class="line">
</span><span class="line"><span class="c">#这里cd到你想下载到的目录, 每个文件的格式如下所示gsod_1901.tar, 发现tar文件竟然只有从1930年才不是空文件</span>
</span><span class="line"><span class="nv">cdir</span><span class="o">=</span><span class="s2">&quot;$(cd `dirname $0`; pwd)&quot;</span>
</span><span class="line">
</span><span class="line"><span class="k">for </span>i in <span class="k">$(</span>seq 1930 1960<span class="k">)</span>
</span><span class="line"><span class="k">do</span>
</span><span class="line"><span class="k">    </span>wget --execute <span class="nv">robots</span><span class="o">=</span>off —accept<span class="o">=</span>tar -r -np -nH --cut-dirs<span class="o">=</span>4 - R index.html* ftp://ftp.ncdc.noaa.gov/pub/data/gsod/<span class="nv">$i</span>/
</span><span class="line"><span class="k">done</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>下载好了之后，我们把这些1930/gsod_1930.tar 之类的文件，重新命令为1930/1930.tar, 然后把所有的文件都放到一个本地的目录，起名叫gsod， 现在gsod目录里都是1930/1930.tar这样的文件了.</p>

<p>接下来我们在hdfs上创建目录，</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">hdfs dfs -mkdir /GSOD /GSOD_ALL
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后将本地的gsod文件夹里的文件都上传到/GSOD/里面去</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">hdfs dfs -put gsod/* /GSOD/
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>这个过程在我的本机上，先是出现了namenode找不到的问题，然后又出现了namenode in safemode，创建不了的问题, 解决办法是</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">stop-all.sh
</span><span class="line">hdfs namenode -format
</span><span class="line">start-all.sh
</span><span class="line">hadoop dfsadmin -safemode leave
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后重新执行</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">hdfs dfs -put gsod/* /GSOD/
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>接下来我们要做的就是在hadoop上处理这些数据了. 首先创建generate_input_list.sh来生成MR的input文件:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c">#!/bin/bash</span>
</span><span class="line">
</span><span class="line"><span class="nv">a</span><span class="o">=</span><span class="nv">$1</span>
</span><span class="line">rm -rf ncdc_files.txt
</span><span class="line">hdfs dfs -rm /ncdc_files.txt
</span><span class="line">
</span><span class="line"><span class="k">while</span> <span class="o">[</span> <span class="nv">$a</span> -le <span class="nv">$2</span> <span class="o">]</span>
</span><span class="line"><span class="k">do</span>
</span><span class="line"><span class="k">        </span><span class="nv">filename</span><span class="o">=</span><span class="s2">&quot;/GSOD/${a}/${a}.tar&quot;</span>
</span><span class="line">        <span class="nb">echo</span> <span class="s2">&quot;$filename&quot;</span> &gt;&gt; ncdc_files.txt
</span><span class="line">        <span class="nv">a</span><span class="o">=</span><span class="sb">`</span>expr <span class="nv">$a</span> + 1<span class="sb">`</span>
</span><span class="line"><span class="k">done</span>
</span><span class="line">
</span><span class="line">hdfs dfs -put ncdc_files.txt /
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>ncdc_files.txt中的每一行就是<code>/GSOD/1950/1950.tar</code>这样的数据.</p>

<p>然后我们来产生文件:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">sh generate_input_list.sh 1901 1956
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>接下来我们来创建load_ncdc_map.sh脚本，在MapReduce的Streaming上正常运行</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c">#!/bin/bash</span>
</span><span class="line">
</span><span class="line"><span class="nb">read </span>offset hdfs_file
</span><span class="line"><span class="nb">echo</span> -e <span class="s2">&quot;$offset\t$hdfs_file&quot;</span>
</span><span class="line">
</span><span class="line"><span class="c"># Retrieve file from HDFS to local disk</span>
</span><span class="line"><span class="nb">echo</span> <span class="s2">&quot;reporter:status:Retrieving $hdfs_file&quot;</span> &gt;&amp;2
</span><span class="line">/Users/sun1/repo/hadoop-3.1.2/bin/hdfs dfs -get <span class="nv">$hdfs_file</span> .
</span><span class="line"><span class="c"># Create local directory</span>
</span><span class="line"><span class="nv">target</span><span class="o">=</span><span class="sb">`</span>basename <span class="nv">$hdfs_file</span> .tar<span class="sb">`</span>
</span><span class="line">mkdir <span class="nv">$target</span>
</span><span class="line">
</span><span class="line"><span class="nb">echo</span> <span class="s2">&quot;reporter:status:Un-tarring $hdfs_file to $target&quot;</span> &gt;&amp;2
</span><span class="line">tar xf <span class="sb">`</span>basename <span class="nv">$hdfs_file</span><span class="sb">`</span> -C <span class="nv">$target</span>
</span><span class="line"><span class="c"># Unzip each station file and concat into one file</span>
</span><span class="line"><span class="nb">echo</span> <span class="s2">&quot;reporter:status:Un-gzipping $target&quot;</span> &gt;&amp;2
</span><span class="line"><span class="k">for </span>file in <span class="nv">$target</span>/*
</span><span class="line"><span class="k">do</span>
</span><span class="line"><span class="k">        </span>gunzip -c <span class="nv">$file</span> &gt;&gt; <span class="nv">$target</span>.all
</span><span class="line">        <span class="nb">echo</span> <span class="s2">&quot;reporter:status:Processed $file&quot;</span> &gt;&amp;2
</span><span class="line"><span class="k">done</span>
</span><span class="line"><span class="c"># Put gzipped version into HDFS</span>
</span><span class="line"><span class="nb">echo</span> <span class="s2">&quot;reporter:status:Gzipping $target and putting in HDFS&quot;</span> &gt;&amp;2
</span><span class="line">gzip -c <span class="nv">$target</span>.all | /Users/sun1/repo/hadoop-3.1.2/bin/hdfs  dfs -put - /GSOD_ALL/<span class="nv">$target</span>.gz
</span><span class="line">rm <span class="sb">`</span>basename <span class="nv">$hdfs_file</span><span class="sb">`</span>
</span><span class="line">rm -r <span class="nv">$target</span>
</span><span class="line">rm <span class="nv">$target</span>.all
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后我们可以使用如下的方式来调用这个shell脚本了:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c">#!/bin/bash</span>
</span><span class="line">
</span><span class="line">hadoop jar <span class="k">${</span><span class="nv">HADOOP_HOME</span><span class="k">}</span>/share/hadoop/tools/lib/hadoop-streaming-3.1.2.jar <span class="se">\</span>
</span><span class="line">    -D mapreduce.job.reduces<span class="o">=</span>0 <span class="se">\</span>
</span><span class="line">    -D mapreduce.map.speculative<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
</span><span class="line">    -D mapreduce.task.timeout<span class="o">=</span>12000000 <span class="se">\</span>
</span><span class="line">    -inputformat org.apache.hadoop.mapred.lib.NLineInputFormat <span class="se">\</span>
</span><span class="line">    -input /ncdc_files.txt <span class="se">\</span>
</span><span class="line">    -output /output/gsod <span class="se">\</span>
</span><span class="line">    -mapper load_ncdc_map.sh <span class="se">\</span>
</span><span class="line">    -file load_ncdc_map.sh
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>最后运行完了，我们可以check下目标文件是否生成</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">hdfs dfs -ls /GSOD_ALL
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>以及检查输出的结果</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">hdfs dfs -cat /output/gsod/part-00053
</span></code></pre></td></tr></table></div></figure></notextile></div>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2019/05/23/zen-yang-wu-xu-shou-dong-shu-ru-mi-ma-lian-jie-postgresql/">怎样无需手动输入密码连接PostgreSQL</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2019-05-23T08:44:13+08:00" pubdate data-updated="true">2019 年5 月23 日</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>我们要想不每次手动输入密码来连接PostgreSQL, 可以在home目录创建一个pgpass文件<code>touch ~/.pgpass</code>.
然后在里面输入如下的信息<code>$host:$port:$db:$user:$password</code>.
这里的每个变量实际过程中替换成真实的值.
然后我们就可以使用如下的方式来进行psql的连接了<code>psql -h $host -p $port -U $user -d $db</code>.
同理，这里的每个变量实际过程中替换成真实的值.</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2019/05/22/shi-yong-rpman-zhuang-crontabming-ling-bei-wang/">使用rpm安装crontab命令备忘</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2019-05-22T16:36:21+08:00" pubdate data-updated="true">2019 年5 月22 日</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>我这边有台ec2, 但是在yum update的时候，总是报错说依赖冲突，后来处理这个问题的时候，过于激进，导致yum不可以用了, 最后把rpm也删了</p>

<p>参考这篇文章
<a href="https://blog.seosiwei.com/detail/27">https://blog.seosiwei.com/detail/27</a>
里的方法2，把rpm和yum都删了然后重装了, 软件下载链接是
<a href="http://mirrors.ustc.edu.cn/centos/6/os/x86_64/Packages/">http://mirrors.ustc.edu.cn/centos/6/os/x86_64/Packages/</a></p>

<p>安装好了之后，发现yum还是不能用，总是报错</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">liblzma.so.0: cannot open shared object file: No such file or directory</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>之类的信息</p>

<p>无可奈何，只好使用rpm了, 我这边需要使用crontab，于是从上面的软件库中下载了</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">cronie-1.4.4-16.el6_8.2.x86_64.rpm``` 和 ```crontabs-1.10-33.el6.noarch.rpm</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后执行如下的命令来安装</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">rpm -Uvh --replacepkgs --nodeps --force cron*.rpm</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后报各种依赖找不到的错误, 比如</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">librpmio.so.3 not found</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>之类的</p>

<p>好在我们有别的ec2，我们可以去这个另外的ec2上找对应的依赖，然后copy到这个我们出问题的机器上</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">find / -name librpm.so.3 -type f</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>然后发现在/usr/lib64中，librpm.so.3是个软连接，指向/usr/lib64中的librpm.so.3.2.2, 我们把librpm.so.3.2.2copy到我们出问题的机器的/usr/lib64里，然后参照
<a href="http://isunix.github.io/blog/2019/05/22/linuxming-ling-lnde-shi-yong-bei-wang/">http://isunix.github.io/blog/2019/05/22/linuxming-ling-lnde-shi-yong-bei-wang/</a>
中的方式来做个软连接</p>

<p>仿照这个方式，如果还有问题，重复找依赖-copy-做软连接的过程</p>

<p>最后再执行</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">rpm -Uvh --replacepkgs --nodeps --force cron*.rpm</span></code></pre></td></tr></table></div></figure></notextile></div>
<p>crontab命令成功安装了.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/12/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/10/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2024/08/29/2022nian-de-gong-zuo-he-sheng-huo-jing-li/">2022年的工作和生活经历</a>
      </li>
    
      <li class="post">
        <a href="/blog/2021/01/04/jupytershang-shi-yong-matplotlibhua-tu-de-%5B%3F%5D-xie-you-yong-de-she-zhi/">Jupyter上使用matplotlib画图的一些有用的设置</a>
      </li>
    
      <li class="post">
        <a href="/blog/2020/12/11/matplotlibhe-seabornshi-yong-fang-fa-ji-jin/">Matplotlib和Seaborn使用方法集锦</a>
      </li>
    
      <li class="post">
        <a href="/blog/2020/12/11/pandasshi-yong-tipsji-jin/">Pandas使用tips集锦</a>
      </li>
    
      <li class="post">
        <a href="/blog/2020/11/20/sparksqlru-men-he-jin-jie/">SparkSQL入门和进阶</a>
      </li>
    
      <li class="post">
        <a href="/blog/2020/02/16/gao-deng-shu-li-tong-ji-xue-qian-yan-zhai-lu/">高等数理统计学前言摘录</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/08/27/%5B%3F%5D-xie-guan-yu-rnnhe-lstmhe-grude-yue-du-cai-liao/">一些关于RNN和LSTM和GRU的阅读材料</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/08/27/ru-he-cha-kan-linuxzhong-de-nei-cun-zhan-yong-qing-kuang/">如何查看Linux中的内存占用情况</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/08/27/sparkzhong-pai-xu-shu-chu/">Spark中排序输出</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/08/14/gradient-boosting-algorithm/">Gradient Boosting 算法的一些资料</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>Categories</h1>
  <ul id="categories">
    <li class='category'><a href='/blog/categories/algorithms/'>Algorithms (8)</a></li>
<li class='category'><a href='/blog/categories/bigdata/'>BigData (10)</a></li>
<li class='category'><a href='/blog/categories/blog/'>Blog (7)</a></li>
<li class='category'><a href='/blog/categories/c/'>C (3)</a></li>
<li class='category'><a href='/blog/categories/data-and-ml-and-ai/'>Data&ML&AI (13)</a></li>
<li class='category'><a href='/blog/categories/django-and-flask/'>Django&Flask (4)</a></li>
<li class='category'><a href='/blog/categories/editor/'>Editor (2)</a></li>
<li class='category'><a href='/blog/categories/javascript/'>Javascript (4)</a></li>
<li class='category'><a href='/blog/categories/linux-and-mac/'>Linux&Mac (13)</a></li>
<li class='category'><a href='/blog/categories/php/'>PHP (5)</a></li>
<li class='category'><a href='/blog/categories/perl/'>Perl (47)</a></li>
<li class='category'><a href='/blog/categories/python/'>Python (11)</a></li>
<li class='category'><a href='/blog/categories/ruby/'>Ruby (1)</a></li>
<li class='category'><a href='/blog/categories/scala/'>Scala (1)</a></li>
<li class='category'><a href='/blog/categories/shell/'>Shell (12)</a></li>
<li class='category'><a href='/blog/categories/gan-wu/'>感悟 (1)</a></li>

  </ul>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2024 - Steven Sun -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
